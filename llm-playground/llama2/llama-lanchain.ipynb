{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a personal assistant\n",
    "\n",
    "The sentence:\n",
    "{sentence}\n",
    "\"\"\"\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Setup the prompt\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create the Chain\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Here's a quick and purr-fect joke for you:\n",
      "\n",
      "Why did the cat join a band? Because he wanted to be the purr-cussionist! ðŸ˜ºðŸŽ¸\n",
      "\n",
      "I hope that made you smile! Do you have any other requests or tasks I can help with as your personal assistant?"
     ]
    }
   ],
   "source": [
    "sentence = \"\"\"\n",
    "tell me a joke about cat\n",
    "\"\"\"\n",
    "async for chunk in chain.astream({\"sentence\": sentence}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masked Sensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a sensitive data identifier and masker. \n",
    "You are capable of identifying sensitive information in text and applying a mask using \"****\". \n",
    "Sensitive data can also be embedded in the context of the text and is not always explicitly mentioned (such as topics about health, financials, addresses, .. )\n",
    "Ensure that Personall identifiable data is detected and masked.\n",
    "Ensure that the detection takes into account the data protection laws and regulations like GDPR, CCPA, and HIPA\n",
    "Ensure that the input text is not altered or changed in any way and just mask the detected sensitive information.\n",
    "Ensure high confidence in the information you mask.\n",
    "The content returned should not include anything other than the text input with the required masking applied.\n",
    "If no sensitive text is detected, return the input as is with no additional content.\n",
    "\n",
    "The sentence:\n",
    "{sentence}\n",
    "\n",
    "Output format: <your_answer>\n",
    "No need explanation, input or extra information \n",
    "\"\"\"\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Setup the prompt\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create the Chain\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last week, while discussing our summer plans, **** hinted he's finally taking that solo trip to Bali he saved up for, after his bonus came through. He received more than 10K as bonus."
     ]
    }
   ],
   "source": [
    "sentence = \"\"\"\n",
    "Last week, while discussing our summer plans, \n",
    "Mike hinted he's finally taking that solo trip to Bali\n",
    "he saved up for, after his bonus came through.\n",
    "He received more than 10K as bonus\n",
    "\"\"\"\n",
    "async for chunk in chain.astream({\"sentence\": sentence}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During our call with Emma, she casually mentioned that ****** is going up to $3000 next month. I noticed that she kept this detail private. It could be due to having some financial concerns."
     ]
    }
   ],
   "source": [
    "sentence = \"\"\"\n",
    "During our call with Emma, she casually mentioned that \n",
    "she's moving because her rent is going up to $3000 next month. \n",
    "I noticed that she kept this detail private. \n",
    "It could be due to having some financial concerns.\n",
    "\"\"\"\n",
    "\n",
    "async for chunk in chain.astream({\"sentence\": sentence}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
