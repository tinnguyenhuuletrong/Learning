{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = Ollama(model=\"llama2\")\n",
    "llm = Ollama(model=\"gemma:2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a personal assistant\n",
    "\n",
    "The sentence:\n",
    "{sentence}\n",
    "\"\"\"\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Setup the prompt\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create the Chain\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a joke about cats:\n",
      "\n",
      "What do you call a cat that's too lazy to do anything?\n",
      "\n",
      "A cuddle puddle!"
     ]
    }
   ],
   "source": [
    "sentence = \"\"\"\n",
    "tell me a joke about cat\n",
    "\"\"\"\n",
    "async for chunk in chain.astream({\"sentence\": sentence}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masked Sensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a sensitive data identifier and masker. \n",
    "You are capable of identifying sensitive information in text and applying a mask using \"****\". \n",
    "Sensitive data can also be embedded in the context of the text and is not always explicitly mentioned (such as topics about health, financials, addresses, .. )\n",
    "Ensure that Personall identifiable data is detected and masked.\n",
    "Ensure that the detection takes into account the data protection laws and regulations like GDPR, CCPA, and HIPA\n",
    "Ensure that the input text is not altered or changed in any way and just mask the detected sensitive information.\n",
    "Ensure high confidence in the information you mask.\n",
    "The content returned should not include anything other than the text input with the required masking applied.\n",
    "If no sensitive text is detected, return the input as is with no additional content.\n",
    "\n",
    "The sentence:\n",
    "{sentence}\n",
    "\n",
    "Output format: <your_answer>\n",
    "No need explanation, input or extra information \n",
    "\"\"\"\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Setup the prompt\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create the Chain\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<input text=\"Last week, while discussing our summer plans, Mike hinted he's finally taking that solo trip to Bali\n",
      "he saved up for, after his bonus came through.\n",
      "He received more than 10K as bonus\">"
     ]
    }
   ],
   "source": [
    "sentence = \"\"\"\n",
    "Last week, while discussing our summer plans, \n",
    "Mike hinted he's finally taking that solo trip to Bali\n",
    "he saved up for, after his bonus came through.\n",
    "He received more than 10K as bonus\n",
    "\"\"\"\n",
    "async for chunk in chain.astream({\"sentence\": sentence}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<input text=\"During our call with Emma, she casually mentioned that she's moving because her rent is going up to $3000 next month. It could be due to having some financial concerns.\" />"
     ]
    }
   ],
   "source": [
    "sentence = \"\"\"\n",
    "During our call with Emma, she casually mentioned that \n",
    "she's moving because her rent is going up to $3000 next month. \n",
    "I noticed that she kept this detail private. \n",
    "It could be due to having some financial concerns.\n",
    "\"\"\"\n",
    "\n",
    "async for chunk in chain.astream({\"sentence\": sentence}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
